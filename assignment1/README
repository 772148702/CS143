README file for Programming Assignment 1 (C++ edition)
=====================================================

Your directory should now contain the following files:

 Makefile        -> [course dir]/src/PA1/Makefile
 README
 cool.flex
 test.cl
 lextest.cc      -> [course dir]/src/PA1/lextest.cc
 mycoolc         -> [course dir]/src/PA1/mycoolc
 stringtab.cc    -> [course dir]/src/PA1/stringtab.cc
 utilities.cc    -> [course dir]/src/PA1/utilities.cc
 handle_flags.cc -> [course dir]/src/PA1/handle_flags.cc
 *.d             dependency files
 *.*             other generated files

The include (.h) files for this assignment can be found in 
[course dir]/include/PA1

	The Makefile contains targets for compiling and running your
	program. DO NOT MODIFY.

	The README contains this info. Part of the assignment is to fill
	the README with the write-up for your project. You should
	explain design decisions, explain why your code is correct, and
	why your test cases are adequate. It is part of the assignment
	to clearly and concisely explain things in text as well as to
	comment your code. Just edit this file.

	cool.flex is a skeleton file for the specification of the
	lexical analyzer. You should complete it with your regular
	expressions, patterns and actions. 

	test.cl is a COOL program that you can test the lexical
	analyzer on. It contains some errors, so it won't compile with
	coolc. However, test.cl does not exercise all lexical
	constructs of COOL and part of your assignment is to rewrite
	test.cl with a complete set of tests for your lexical analyzer.

	cool-parse.h contains definitions that are used by almost all parts
	of the compiler. DO NOT MODIFY.

	stringtab.{cc|h} and stringtab_functions.h contains functions
        to manipulate the string tables.  DO NOT MODIFY.

	utilities.{cc|h} contains functions used by the main() part of
	the lextest program. You may want to use the strdup() function
	defined in here. Remember that you should not print anything
	from inside cool.flex! DO NOT MODIFY.

	lextest.cc contains the main function which will call your
	lexer and print out the tokens that it returns.  DO NOT MODIFY.

	mycoolc is a shell script that glues together the phases of the
	compiler using Unix pipes instead of statically linking code.  
	While inefficient, this architecture makes it easy to mix and match
	the components you write with those of the course compiler.
	DO NOT MODIFY.	

        cool-lexer.cc is the scanner generated by flex from cool.flex.
        DO NOT MODIFY IT, as your changes will be overritten the next
        time you run flex.

 	The *.d files are automatically generated Makefiles that capture
 	dependencies between source and header files in this directory.
 	These files are updated automatically by Makefile; see the gmake
 	documentation for a detailed explanation.

Instructions
------------

	To compile your lextest program type:

	% make lexer

	Run your lexer by putting your test input in a file 'foo.cl' and
	run the lextest program:

	% ./lexer foo.cl

	To run your lexer on the file test.cl type:

	% make dotest

	If you think your lexical analyzer is correct and behaves like
	the one we wrote, you can actually try 'mycoolc' and see whether
	it runs and produces correct code for any examples.
	If your lexical analyzer behaves in an
	unexpected manner, you may get errors anywhere, i.e. during
	parsing, during semantic analysis, during code generation or
	only when you run the produced code on spim. So beware.

	To turn in your work type:

	% make submit

	Running "submit" will collect the files cool.flex, test.cl,
	README, and test.output. Don't forget to edit the README file to
	include your write-up, and to write your own test cases in
	test.cl.

 	You may turn in the assignment as many times as you like.
	However, only the last version will be retained for
	grading.

	If you change architectures you must issue

	% make clean

	when you switch from one type of machine to the other.
	If at some point you get weird errors from the linker,	
	you probably forgot this step.

	GOOD LUCK!

---8<------8<------8<------8<---cut here---8<------8<------8<------8<---

Write-up for PA1
----------------
=======================================================================
                       Overall structure
=======================================================================
The lexical units of Cool are integers, type identifiers, object 
identifiers, special notaitons, strings, keywords and white space.

Our lexer has three states which is COMMENT, COMMENT_DASH,
STRING STRERROR and INITIAL state.
The five states handle the below different lexical units respectively.
  COMMENT ---- any comments inside (* *)
  COMMENT_DASH ---- any comments between -- and a new line character
  STRING  ---- strings
  STRERROR ---- strings encountered errors (e.g. contains null)  
  INITIAL  ---- integers, type identifiers, object identifiers, 
                special notaitons, keywords and white space.

The order we used to analysis those units is:
1. comments, we need to remove any contents inside the comment first, 
   because anything inside the comment will not be passed to parser.
2. strings, strings begin with ", when input stream encountered ", it 
   will jump to string state. 
3. keywords, we need to match keywords before identifiers, because if 
   we change this order, we may end up with matching some keywords to 
   identifiers, which is obviously wrong.
4. special notaitons
5. identifiers
6. integers
7. white space, We give white space the lowest priority, because if we
   put white space before identifiers or keywords, this may remove 
   white space too early, resulting in reading modified tokens.(e.g. 
   if then become ifthen, two keywords become an identifier) 
======================================================================
                        Design rules
======================================================================
-------------------design rules for comments -------------------------

-------------------design rules for strings---------------------------

-------------------design rules for keywords--------------------------
All the keywords except true and false, are all case insensitive, so 
we active the case insensitive option, and make the following 
definitions for keywords:
CLASS          ?i:class

And for true and false whose first character is case sensitive and must
be lowere case, we use the following definitions:
TRUE           (?-i:t)(?i:rue)
FALSE          (?-i:f)(?i:alse)

------------------ design rules for identifiers-----------------------
Type identifiers begin with a capital letter, object identifiers begin
with a lower case letter, so we first build a capital and a lower group
for all characters, 
CAPITAL        [A-Z]
LOWER          [a-z]
then make the following definitions for type identifiers and object 
identifiers:
OBJECTID       {LOWER}({CHAR}|{DIGIT}|"_")*
TYPEID         {CAPITAL}({CHAR}|{DIGIT}|"_")*
For the two special identifiers self and SELF_TYPE, we just use:
SELFID         "self"
SELF_TYPEID    "SELF_TYPE"

-------------------design rules for others----------------------------
For integers, we use:
DIGIT          [0-9]
INTEGER       {DIGIT}+

For special notaitons, It is a "feature" of flex that single character 
tokens may use their ASCII code as their token ID, and aren't typically
given #define's for their token value. (This is also why the numeric 
values for multi-character tokens traditionally start at 256, one more
than the largest 8-bit ASCII value.) So when we return the token ID 
for special notaitons, we just use their ASCII value.

If an input cannot be matched to any of the above rules, an error 
message will be generated. 
======================================================================
                            Test
======================================================================

